{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "세가지 프로젝트.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **1-11. 프로젝트 (1) load_digits : 손글씨를 분류해 봅시다**"
      ],
      "metadata": {
        "id": "SCpVsGXgLLXq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "id": "82-KlECQc3IH",
        "outputId": "d67df36e-1505-4174-d7fb-a1a2c16e449b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.  0.  5. ...  0.  0.  0.]\n",
            " [ 0.  0.  0. ... 10.  0.  0.]\n",
            " [ 0.  0.  0. ... 16.  9.  0.]\n",
            " ...\n",
            " [ 0.  0.  1. ...  6.  0.  0.]\n",
            " [ 0.  0.  2. ... 12.  0.  0.]\n",
            " [ 0.  0. 10. ... 12.  1.  0.]]\n",
            "[0 1 2 ... 8 9 8]\n",
            "['DESCR', 'data', 'feature_names', 'frame', 'images', 'target', 'target_names']\n",
            "Accuracy score: \n",
            "Decision Tree:  0.8444444444444444\n",
            "Random Forest:  0.9777777777777777\n",
            "SVM:  0.9833333333333333\n",
            "SGD:  0.9611111111111111\n",
            "Linear Regression:  0.9694444444444444\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAADyUlEQVR4nO3dUVFjaRRG0T9TYyAWggSwkkgACSABL5FAJBALSCAS7higeZo6vZte6zF5+KiEXbeKB85u27YF9Pzzu38A4GvihChxQpQ4IUqcEPXvd2/udrsf+afc4/E4uvf6+jq2dblcxrZeXl7Gtm6329jWtG3bdl+97skJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEqG/PMfxUk+cR1lrrcDiMbe33+7Gtz8/Psa3T6TS2tdZa5/N5dO8rnpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IypxjuL+/H9uaPI+w1lp3d3djWx8fH2Nbb29vY1uTvx9rOccAfEOcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiMrcStnv92Nb1+t1bGut2fslk6Y/x7+NJydEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROi/spzDJfLZWzrJ5v8zm6329hWhScnRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTojLnGCb/3f79/f3Y1rTJEwmTn+P5fB7bqvDkhChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQtRu27Zfv7nb/frN/9nhcJiaWu/v72Nba6319PQ0tnU8Hse2Jr+zh4eHsa1p27btvnrdkxOixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oSozK2USY+Pj6N7z8/PY1vX63Vs63Q6jW39ZG6lwB9GnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBD17TkG4Pfx5IQocUKUOCFKnBAlTogSJ0T9ByioUst9Wxj9AAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "#데이터 준비\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.metrics import accuracy_score, recall_score, f1_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "digits = load_digits()\n",
        "digits_data = digits.data\n",
        "digits_label = digits.target\n",
        "digits_feature = digits.feature_names\n",
        "print(digits_data)\n",
        "print (digits_label)\n",
        "print(dir(digits))\n",
        "\n",
        "plt.imshow(digits.data[0].reshape(8, 8), cmap='gray')\n",
        "plt.axis('off')\n",
        "digits_label[:20]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(digits_data, digits_label,test_size=0.2,random_state=15) \n",
        "\n",
        "##################  Decision Tree  #######################\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "decision_tree = DecisionTreeClassifier(random_state=15)\n",
        "decision_tree.fit(X_train, y_train)\n",
        "y_pred = decision_tree.predict(X_test)\n",
        "DT_accuracy = accuracy_score(y_test, y_pred) \n",
        "\n",
        "\n",
        "#####################  Random Forest  ####################\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "random_forest = RandomForestClassifier(random_state=32)\n",
        "random_forest.fit(X_train, y_train)\n",
        "y_pred = random_forest.predict(X_test)\n",
        "RF_accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "\n",
        "############ SVM (Support Vector Machine)  ################\n",
        "from sklearn import svm\n",
        "svm_model = svm.SVC()\n",
        "svm_model.fit(X_train, y_train)\n",
        "y_pred = svm_model.predict(X_test)\n",
        "SVM_accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "\n",
        "####### SGD (Stochastic Gradient Descent) Classifier  #######\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "sgd_model = SGDClassifier()\n",
        "sgd_model.fit(X_train, y_train)\n",
        "y_pred = sgd_model.predict(X_test)\n",
        "SGD_accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "####################  Logistic Regression  ######################\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "logistic_model = LogisticRegression(max_iter=5000)\n",
        "logistic_model.fit(X_train, y_train)\n",
        "y_pred = logistic_model.predict(X_test)\n",
        "LR_accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "####################################################################\n",
        "# 혼돈 Matrix 중에서 accuracy를 선택하여 정확도를 측정하였습니다.\n",
        "# accuracy 를 선택한 이유는 데이터 분포를 봤을 때 골고루 분포되어 \n",
        "# 있어서 굳이 precision 이나 혹은 recall 을 쓰지 않아도 된다고 판단 되었고\n",
        "# Accuracy는 전체 예상한것 중 바르게 분류한 비율 TP/(TP+TN+FT+FN)을 \n",
        "# 나타내고 모델을 평가할때 그 값이 의미가 있다고 생각됩니다.\n",
        "# SVM 모델의 accuracy 값이 0.983으로 가장 높게 나왔습니다.\n",
        "##################################################################### \n",
        "print(\"Accuracy score: \")\n",
        "print(\"Decision Tree: \" , DT_accuracy)\n",
        "print(\"Random Forest: \", RF_accuracy)\n",
        "print(\"SVM: \" , SVM_accuracy)\n",
        "print(\"SGD: \", SGD_accuracy)\n",
        "print(\"Linear Regression: \" , LR_accuracy)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1-12. 프로젝트 (2) load_wine : 와인을 분류해 봅시다**"
      ],
      "metadata": {
        "id": "DASoIXjF0Dsq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "wine = load_wine()\n",
        "wine_data = wine.data\n",
        "wine_feature = wine.feature_names\n",
        "print(wine_feature)\n",
        "wine_label = wine.target\n",
        "print(wine_label)\n",
        "print(dir(wine))\n",
        "\n",
        "#train, test 데이터 분리\n",
        "X_train, X_test, y_train, y_test = train_test_split(wine_data, \n",
        "                                                    wine_label, \n",
        "                                                    test_size=0.2, \n",
        "                                                    random_state=7)\n",
        "\n",
        "\n",
        "##################  Decision Tree  #######################\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "decision_tree = DecisionTreeClassifier(random_state=15)\n",
        "decision_tree.fit(X_train, y_train)\n",
        "y_pred = decision_tree.predict(X_test)\n",
        "print(y_train)\n",
        "DT_accuracy = accuracy_score(y_test, y_pred) \n",
        "\n",
        "\n",
        "#####################  Random Forest  ####################\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "random_forest = RandomForestClassifier(random_state=32)\n",
        "random_forest.fit(X_train, y_train)\n",
        "y_pred = random_forest.predict(X_test)\n",
        "RF_accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "\n",
        "############ SVM (Support Vector Machine)  ################\n",
        "from sklearn import svm\n",
        "svm_model = svm.SVC()\n",
        "svm_model.fit(X_train, y_train)\n",
        "y_pred = svm_model.predict(X_test)\n",
        "SVM_accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "\n",
        "####### SGD (Stochastic Gradient Descent) Classifier  #######\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "sgd_model = SGDClassifier()\n",
        "sgd_model.fit(X_train, y_train)\n",
        "y_pred = sgd_model.predict(X_test)\n",
        "SGD_accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "\n",
        "####################  Logistic Regression  ######################\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "logistic_model = LogisticRegression(max_iter=5000)\n",
        "logistic_model.fit(X_train, y_train)\n",
        "y_pred = logistic_model.predict(X_test)\n",
        "LR_accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "#######################################################################\n",
        "# 혼돈 Matrix 중에서 accuracy를 선택하여 정확도를 측정하였습니다.\n",
        "# accuracy 를 선택한 이유는 데이터 분포를 봤을 때 골고루 분포되어 \n",
        "# 있어서 굳이 precision 이나 혹은 recall 을 쓰지 않아도 된다고 판단 되었고\n",
        "# Accuracy는 전체 예상한것 중 바르게 분류한 비율 TP/(TP+TN+FT+FN)을 \n",
        "# 나타내는데 와인 종류를 분류하는 모델을 평가할때 그 accuracy 값이 의미가 \n",
        "# 있다고 생각됩니다.\n",
        "# Linear Regression 모델의 accuracy 값이 0.972 로 가장 높게 나왔습니다.\n",
        "#######################################################################\n",
        "print(\"Accuracy score: \")\n",
        "print(\"Decision Tree: \" , DT_accuracy)\n",
        "print(\"Random Forest: \", RF_accuracy)\n",
        "print(\"SVM: \" , SVM_accuracy)\n",
        "print(\"SGD: \", SGD_accuracy)\n",
        "print(\"Linear Regression: \" , LR_accuracy)"
      ],
      "metadata": {
        "id": "J2TvJZ6O0CXO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "558c7544-c570-4c44-d1b1-639cd2cca210"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline']\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "['DESCR', 'data', 'feature_names', 'frame', 'target', 'target_names']\n",
            "[2 2 0 2 0 1 2 2 1 0 0 1 1 1 1 1 0 0 1 1 1 0 2 0 2 1 2 0 2 1 1 1 0 1 0 0 2\n",
            " 0 2 1 1 2 1 0 1 1 1 1 0 0 0 1 1 2 1 0 1 2 0 1 0 2 1 0 0 0 0 1 1 0 1 1 0 0\n",
            " 0 0 2 2 0 0 0 2 0 0 1 2 1 1 0 0 2 0 2 2 2 1 2 1 2 1 0 0 2 1 2 1 1 0 1 2 1\n",
            " 2 0 0 2 0 1 2 0 1 0 0 0 0 1 0 2 1 1 2 0 1 1 1 0 2 1 1 2 1 0 2]\n",
            "Accuracy score: \n",
            "Decision Tree:  0.9166666666666666\n",
            "Random Forest:  1.0\n",
            "SVM:  0.6111111111111112\n",
            "SGD:  0.4722222222222222\n",
            "Linear Regression:  0.9722222222222222\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1-13. 프로젝트 (3) load_breast_cancer : 유방암 여부를 진단해 봅시다** "
      ],
      "metadata": {
        "id": "zKJTrIO4TUyY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import recall_score\n",
        "breast_cancer = load_breast_cancer()\n",
        "breast_cancer_data = breast_cancer.data\n",
        "breast_cancer_feature = breast_cancer.feature_names\n",
        "print (breast_cancer_feature )\n",
        "breast_cancer_label = breast_cancer.target\n",
        "print(breast_cancer_label)\n",
        "print(dir(breast_cancer))\n",
        "\n",
        "#train, test 데이터 분리\n",
        "X_train, X_test, y_train, y_test = train_test_split(wine_data, \n",
        "                                                    wine_label, \n",
        "                                                    test_size=0.2, \n",
        "                                                    random_state=7)\n",
        "\n",
        "\n",
        "#####################  Decision Tree  ##########################\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "decision_tree = DecisionTreeClassifier(random_state=15)\n",
        "decision_tree.fit(X_train, y_train)\n",
        "y_pred = decision_tree.predict(X_test)\n",
        "DT_recall_score = recall_score(y_test, y_pred, average = 'macro')\n",
        "\n",
        "\n",
        "#####################  Random Forest  ####################\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "random_forest = RandomForestClassifier(random_state=32)\n",
        "random_forest.fit(X_train, y_train)\n",
        "y_pred = random_forest.predict(X_test)\n",
        "RF_recall_score = recall_score(y_test, y_pred, average = 'macro')\n",
        "print(recall_score)\n",
        "\n",
        "\n",
        "############ SVM (Support Vector Machine)  ################\n",
        "from sklearn import svm\n",
        "svm_model = svm.SVC()\n",
        "svm_model.fit(X_train, y_train)\n",
        "y_pred = svm_model.predict(X_test)\n",
        "SVM_recall_score = recall_score(y_test, y_pred, average = 'macro')\n",
        "\n",
        "\n",
        "####### SGD (Stochastic Gradient Descent) Classifier  #######\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "sgd_model = SGDClassifier()\n",
        "sgd_model.fit(X_train, y_train)\n",
        "y_pred = sgd_model.predict(X_test)\n",
        "SGD_recall_score = recall_score(y_test, y_pred, average = 'macro')\n",
        "\n",
        "\n",
        "####################  Logistic Regression  ######################\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "logistic_model = LogisticRegression(max_iter= 5000)\n",
        "logistic_model.fit(X_train, y_train)\n",
        "y_pred = logistic_model.predict(X_test)\n",
        "LR_recall_score = recall_score(y_test, y_pred, average = 'macro')\n",
        "\n",
        "\n",
        "#############################################################################\n",
        "# 암의 악성 여부를 분류할때는 지표로 혼돈 Matrix중 Recall의 값을 보는\n",
        "# 것이 적합할 것 같습니다. Recall(재현율) 은 실제값이 positive인것 중 positive라고 \n",
        "# 분류한 비율입니다 (TP/TP+FN). Positive인데 positive라고 분류하지 않은 것에 대해 \n",
        "# 그 값이 분모에서 전체 값을 감점 시킵니다. 악성암여부를 판단할때는 암인데 암이 아니라고 \n",
        "# 판단하면 심각한 문제가 됩니다. 암이 아닌데 암이라고 분류하는 것은 상대적으로 큰\n",
        "# 오류가 되지 않습니다. Precision(정밀도)는 positive라고 분류한 것 중 실제로 positive 인 \n",
        "# 비율입니다. 만약 precision 을 사용한다면 악성암이라고 분류한 것중 얼마나 많이 \n",
        "# 악성암인지를 보는 것인데, 악성암 positive를 많이 놏치고도 높은 점수가 나올수 있기\n",
        "# 때문에 적합하지 않습니다. 비슷한 논리로 Accuracy 보다 recall이 더 적합하다고 할 수 \n",
        "# 있습니다.\n",
        "# Random Forest 가 1.0으로 가장 높게 나왔습니다.\n",
        "#############################################################################\n",
        "print(\"Recall Score: \")\n",
        "print(\"Decision Tree: \" , DT_accuracy)\n",
        "print(\"Random Forest: \", RF_accuracy)\n",
        "print(\"SVM: \" , SVM_accuracy)\n",
        "print(\"SGD: \", SGD_accuracy)\n",
        "print(\"Linear Regression: \" , LR_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bGtjGa7TYMt",
        "outputId": "c0f64a91-ca39-40ac-d6f2-11286de9be75"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
            " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
            " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
            " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
            " 'smoothness error' 'compactness error' 'concavity error'\n",
            " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
            " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
            " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
            " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 1 0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 0 0 1 0 0 1 1 1 1 0 1 0 0 1 1 1 1 0 1 0 0\n",
            " 1 0 1 0 0 1 1 1 0 0 1 0 0 0 1 1 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1\n",
            " 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 0 0 1 0 1 0 0 1 0 0 1 1 0 1 1 0 1 1 1 1 0 1\n",
            " 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 0 0 1 0\n",
            " 1 0 1 1 1 0 1 1 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1 1 0 1 0 0 0 0 1 1 0 0 1 1\n",
            " 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 0 0 0 1 1\n",
            " 1 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0\n",
            " 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
            " 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 0 1 1\n",
            " 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1\n",
            " 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 1 1 0 1 0 1 0 0\n",
            " 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 0 0 0 0 0 0 1]\n",
            "['DESCR', 'data', 'data_module', 'feature_names', 'filename', 'frame', 'target', 'target_names']\n",
            "<function recall_score at 0x7fb3e4fae9e0>\n",
            "Recall Score: \n",
            "Decision Tree:  0.9166666666666666\n",
            "Random Forest:  1.0\n",
            "SVM:  0.6111111111111112\n",
            "SGD:  0.4722222222222222\n",
            "Linear Regression:  0.9722222222222222\n"
          ]
        }
      ]
    }
  ]
}